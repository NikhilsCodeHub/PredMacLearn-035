<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Predmaclearn-035 by NikhilsCodeHub</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Predmaclearn-035</h1>
      <h2 class="project-tagline">Practical Machine Learning - Coursera</h2>
      <a href="https://github.com/NikhilsCodeHub/PredMacLearn-035" class="btn">View on GitHub</a>
      <a href="https://github.com/NikhilsCodeHub/PredMacLearn-035/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/NikhilsCodeHub/PredMacLearn-035/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="description" class="anchor" href="#description" aria-hidden="true"><span class="octicon octicon-link"></span></a>Description</h3>

<p>In this project, the goal will be to use data from accelerometers on the
belt, forearm, arm, and dumbell of 6 participants. They were asked to
perform barbell lifts correctly and incorrectly in 5 different ways. The
objective of the project is to predict the manner in which they did the
exercise.</p>

<p>The training data for this project is available here:</p>

<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a></p>

<p>The test data is available here:</p>

<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a></p>

<p>The data for this project is obtained from this source:
<a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>.</p>

<p>When you click the <strong>Knit</strong> button a document will be generated that
includes both content as well as the output of any embedded R code
chunks within the document. You can embed an R code chunk like this:</p>

<h3>
<a id="analysis" class="anchor" href="#analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysis</h3>

<h4>
<a id="download-data" class="anchor" href="#download-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Download Data.</h4>

<pre><code>url_train &lt;- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

url_test &lt;- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

download.file(url = url_train, destfile = "pml-training.csv")

download.file(url = url_test, destfile = "pml-testing.csv")
</code></pre>

<h3>
<a id="getting-and-cleaning-data" class="anchor" href="#getting-and-cleaning-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting and Cleaning Data</h3>

<pre><code>pml_train &lt;- read.csv("pml-training.csv", stringsAsFactors = FALSE, na.strings = c("", " "))

pml_test &lt;- read.csv("pml-testing.csv", stringsAsFactors = FALSE, na.strings = c("", " "))
</code></pre>

<h4>
<a id="peek-at-the-data" class="anchor" href="#peek-at-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Peek at the data</h4>

<pre><code>## Limiting the output for clarity
str(pml_train, list.len=10)

## 'data.frame':    19622 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : chr  "carlitos" "carlitos" "carlitos" "carlitos" ...
##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp          : chr  "05/12/2011 11:23" "05/12/2011 11:23" "05/12/2011 11:23" "05/12/2011 11:23" ...
##  $ new_window              : chr  "no" "no" "no" "no" ...
##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##   [list output truncated]

str(pml_test , list.len=10)

## 'data.frame':    20 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : chr  "pedro" "jeremy" "jeremy" "adelmo" ...
##  $ raw_timestamp_part_1    : int  1323095002 1322673067 1322673075 1322832789 1322489635 1322673149 1322673128 1322673076 1323084240 1322837822 ...
##  $ raw_timestamp_part_2    : int  868349 778725 342967 560311 814776 510661 766645 54671 916313 384285 ...
##  $ cvtd_timestamp          : chr  "05/12/2011 14:23" "30/11/2011 17:11" "30/11/2011 17:11" "02/12/2011 13:33" ...
##  $ new_window              : chr  "no" "no" "no" "no" ...
##  $ num_window              : int  74 431 439 194 235 504 485 440 323 664 ...
##  $ roll_belt               : num  123 1.02 0.87 125 1.35 -5.92 1.2 0.43 0.93 114 ...
##  $ pitch_belt              : num  27 4.87 1.82 -41.6 3.33 1.59 4.44 4.15 6.72 22.4 ...
##  $ yaw_belt                : num  -4.75 -88.9 -88.5 162 -88.6 -87.7 -87.3 -88.5 -93.7 -13.1 ...
##   [list output truncated]
</code></pre>

<p>From the above we see that features 1-7 are metadata in Training
dataset. In the Test dataset we have "Problem_id" in addition to above.
So we'll remove those columns from the dataset. The remainig features
are all numeric, so it's good idea to explicitly convert these to
numeric datatype, as some may not have converted automatically while
reading.</p>

<h4>
<a id="clean-and-convert-to-numeric" class="anchor" href="#clean-and-convert-to-numeric" aria-hidden="true"><span class="octicon octicon-link"></span></a>Clean and Convert to Numeric</h4>

<pre><code># Remove metadata columns.
pml_train &lt;- pml_train[,-c(1:7)]
pml_test &lt;- pml_test[,-c(1:7,160)]

# convert all columns to Numeric except 'classe'
pml_train[,c(1:152)]&lt;- sapply(pml_train[,c(1:152)],as.numeric)
pml_test[,c(1:152)]&lt;- sapply(pml_test[,c(1:152)],as.numeric)
</code></pre>

<p>Next it's observed that there are several features with NA data. As the
data has been gathered via sensors, imputing missing values will not
yield correct results. Therefore it'd be appropriate to discard those
features/columns.</p>

<pre><code>## identify NA columns
na.cols&lt;- sapply(pml_train[,1:152], anyNA)
summary(na.cols)

##    Mode   FALSE    TRUE    NA's 
## logical      52     100       0

#Filter NA columns
d_train&lt;-pml_train[,!na.cols]
dim(d_train)

## [1] 19622    53
</code></pre>

<h4>
<a id="split-data-for-cross-validation" class="anchor" href="#split-data-for-cross-validation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Split Data for cross validation.</h4>

<p>Now we'll partition data for cross validation purpose. For the purpose
of this project we'll implement a 60/40 split based on the 'classe'
variable.</p>

<pre><code># Load required packages

library(caret)

## Loading required package: lattice
## Loading required package: ggplot2

library(randomForest)

## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.

# Split pml_train into Train and Test Set 

d&lt;- createDataPartition(d_train$classe,p=.60, list=FALSE )

t_train &lt;- d_train[d,]
t_test &lt;- d_train[-d,]
</code></pre>

<h4>
<a id="model-fit" class="anchor" href="#model-fit" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model Fit</h4>

<pre><code>## Using Random Forest Algorithm

set.seed(2016)
d_fit &lt;- randomForest(as.factor(classe)~., data = t_train, importance = TRUE, ntree=500)
</code></pre>

<h4>
<a id="taking-a-look-at-the-model" class="anchor" href="#taking-a-look-at-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Taking a look at the model</h4>

<pre><code>d_fit

## 
## Call:
##  randomForest(formula = as.factor(classe) ~ ., data = t_train,      importance = TRUE, ntree = 500) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 7
## 
##         OOB estimate of  error rate: 0.7%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3344    3    1    0    0 0.001194743
## B   11 2260    8    0    0 0.008336990
## C    0   21 2030    3    0 0.011684518
## D    0    0   24 1904    2 0.013471503
## E    0    0    1    8 2156 0.004157044
</code></pre>

<p>From above it's observed that the Out-Of-Bag error rate is <code>0.51%</code></p>

<h4>
<a id="variable-importance-plot" class="anchor" href="#variable-importance-plot" aria-hidden="true"><span class="octicon octicon-link"></span></a>Variable Importance Plot</h4>

<p>Here lets observe which features were considered in the model and it's
importance as given by Accuracy metric.</p>

<pre><code>varImpPlot(d_fit, sort = TRUE, n.var = 15 , main = "Variable Importance Plot", pch=16, type = 1)
</code></pre>

<p><img src="Analysis_files/figure-markdown_strict/unnamed-chunk-10-1.png" alt=""></p>

<h4>
<a id="validating-the-model" class="anchor" href="#validating-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Validating the model</h4>

<p>Here we'll predict the <code>classe</code> outcome for out partitioned test data
from the training set. This will confirmation if the model is a good fit
or not. Running the confusion matrix gives us the Accuracy, Sensitivity
and Specificity of the predictions.</p>

<pre><code>pred_t_test &lt;- predict(d_fit, t_test, type="class")
p&lt;- data.frame(pred_t_test, stringsAsFactors = FALSE)
confusionMatrix(t_test$classe, p$pred_t_test)

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2230    1    0    0    1
##          B    7 1506    5    0    0
##          C    0    9 1358    1    0
##          D    0    0   12 1274    0
##          E    0    0    0    1 1441
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9953          
##                  95% CI : (0.9935, 0.9967)
##     No Information Rate : 0.2851          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.994           
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9969   0.9934   0.9876   0.9984   0.9993
## Specificity            0.9996   0.9981   0.9985   0.9982   0.9998
## Pos Pred Value         0.9991   0.9921   0.9927   0.9907   0.9993
## Neg Pred Value         0.9988   0.9984   0.9974   0.9997   0.9998
## Prevalence             0.2851   0.1932   0.1752   0.1626   0.1838
## Detection Rate         0.2842   0.1919   0.1731   0.1624   0.1837
## Detection Prevalence   0.2845   0.1935   0.1744   0.1639   0.1838
## Balanced Accuracy      0.9983   0.9958   0.9930   0.9983   0.9996
</code></pre>

<p>From above metrics, it appears that our model Accuracy of 99%. This is
a very confident measure, so now we can run the test dataset on this
model for prediction.</p>

<h4>
<a id="predicting-on-the-given-test-dataset" class="anchor" href="#predicting-on-the-given-test-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Predicting on the given test dataset.</h4>

<pre><code>pred_pml_test &lt;- predict(d_fit, pml_test, type="class")
pred_pml_test

##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E
</code></pre>

<h4>
<a id="generate-prediction-submission-files" class="anchor" href="#generate-prediction-submission-files" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generate Prediction Submission Files</h4>

<pre><code>pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

# Run the function to generate the submission files.
pml_write_files(pred_pml_test)
</code></pre>

<h2>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>

<p>As the accuracy of our model is 99% and the error rate is quite low 0.7%, we can conclude that the predictions for test data would be quite accurate.</p>

<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E
</code></pre>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/NikhilsCodeHub/PredMacLearn-035">Predmaclearn-035</a> is maintained by <a href="https://github.com/NikhilsCodeHub">NikhilsCodeHub</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
