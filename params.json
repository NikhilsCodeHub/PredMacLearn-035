{"name":"Predmaclearn-035","tagline":"Practical Machine Learning - Coursera","body":"---\r\ntitle: \"Activity Tracker Analysis\"\r\noutput: \r\n        html_document\r\n---\r\n\r\n## Description \r\n\r\nIn this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. \r\nThe objective of the project is to predict the manner in which they did the exercise.\r\n\r\nThe training data for this project is available here: \r\n\r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\r\n\r\nThe test data is available here: \r\n\r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\r\n\r\nThe data for this project is obtained from this source: http://groupware.les.inf.puc-rio.br/har. \r\n\r\nWhen you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\r\n\r\n## Analysis\r\n\r\n#### Download Data.\r\n\r\n```r\r\nurl_train <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\r\n\r\nurl_test <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\r\n\r\ndownload.file(url = url_train, destfile = \"pml-training.csv\")\r\n\r\ndownload.file(url = url_test, destfile = \"pml-testing.csv\")\r\n```\r\n\r\n\r\n### Getting and Cleaning Data\r\n\r\n\r\n\r\n```r\r\npml_train <- read.csv(\"pml-training.csv\", stringsAsFactors = FALSE, na.strings = c(\"\", \" \"))\r\n\r\npml_test <- read.csv(\"pml-testing.csv\", stringsAsFactors = FALSE, na.strings = c(\"\", \" \"))\r\n```\r\n\r\n#### Peek at the data\r\n\r\n```r\r\n## Limiting the output for clarity\r\nstr(pml_train, list.len=10)\r\n```\r\n\r\n```\r\n## 'data.frame':\t19622 obs. of  160 variables:\r\n##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...\r\n##  $ user_name               : chr  \"carlitos\" \"carlitos\" \"carlitos\" \"carlitos\" ...\r\n##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...\r\n##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...\r\n##  $ cvtd_timestamp          : chr  \"05/12/2011 11:23\" \"05/12/2011 11:23\" \"05/12/2011 11:23\" \"05/12/2011 11:23\" ...\r\n##  $ new_window              : chr  \"no\" \"no\" \"no\" \"no\" ...\r\n##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...\r\n##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...\r\n##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...\r\n##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...\r\n##   [list output truncated]\r\n```\r\n\r\n```r\r\nstr(pml_test , list.len=10)\r\n```\r\n\r\n```\r\n## 'data.frame':\t20 obs. of  160 variables:\r\n##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...\r\n##  $ user_name               : chr  \"pedro\" \"jeremy\" \"jeremy\" \"adelmo\" ...\r\n##  $ raw_timestamp_part_1    : int  1323095002 1322673067 1322673075 1322832789 1322489635 1322673149 1322673128 1322673076 1323084240 1322837822 ...\r\n##  $ raw_timestamp_part_2    : int  868349 778725 342967 560311 814776 510661 766645 54671 916313 384285 ...\r\n##  $ cvtd_timestamp          : chr  \"05/12/2011 14:23\" \"30/11/2011 17:11\" \"30/11/2011 17:11\" \"02/12/2011 13:33\" ...\r\n##  $ new_window              : chr  \"no\" \"no\" \"no\" \"no\" ...\r\n##  $ num_window              : int  74 431 439 194 235 504 485 440 323 664 ...\r\n##  $ roll_belt               : num  123 1.02 0.87 125 1.35 -5.92 1.2 0.43 0.93 114 ...\r\n##  $ pitch_belt              : num  27 4.87 1.82 -41.6 3.33 1.59 4.44 4.15 6.72 22.4 ...\r\n##  $ yaw_belt                : num  -4.75 -88.9 -88.5 162 -88.6 -87.7 -87.3 -88.5 -93.7 -13.1 ...\r\n##   [list output truncated]\r\n```\r\n\r\nFrom the above we see that features 1-7 are metadata in Training dataset. In the Test dataset we have \"Problem_id\" in addition to above. So we'll remove those columns from the dataset.\r\nThe remainig features are all numeric, so it's good idea to explicitly convert these to numeric datatype, as some may not have converted automatically while reading.\r\n\r\n#### Clean and Convert to Numeric\r\n\r\n```r\r\n# Remove metadata columns.\r\npml_train <- pml_train[,-c(1:7)]\r\npml_test <- pml_test[,-c(1:7,160)]\r\n\r\n# convert all columns to Numeric except 'classe'\r\npml_train[,c(1:152)]<- sapply(pml_train[,c(1:152)],as.numeric)\r\npml_test[,c(1:152)]<- sapply(pml_test[,c(1:152)],as.numeric)\r\n```\r\n\r\nNext it's observed that there are several features with NA data. As the data has been gathered via sensors, imputing missing values will not yield correct results. Therefore it'd be appropriate to discard those features/columns.\r\n\r\n\r\n```r\r\n## identify NA columns\r\nna.cols<- sapply(pml_train[,1:152], anyNA)\r\nsummary(na.cols)\r\n```\r\n\r\n```\r\n##    Mode   FALSE    TRUE    NA's \r\n## logical      52     100       0\r\n```\r\n\r\n```r\r\n#Filter NA columns\r\nd_train<-pml_train[,!na.cols]\r\ndim(d_train)\r\n```\r\n\r\n```\r\n## [1] 19622    53\r\n```\r\n\r\n#### Split Data for cross validation.\r\nNow we'll partition data for cross validation purpose.\r\nFor the purpose of this project we'll implement a 60/40 split based on the 'classe' variable. \r\n\r\n\r\n```r\r\n# Load required packages\r\n\r\nlibrary(caret)\r\nlibrary(randomForest)\r\n```\r\n\r\n\r\n```r\r\n# Split pml_train into Train and Test Set \r\n\r\nd<- createDataPartition(d_train$classe,p=.60, list=FALSE )\r\n\r\nt_train <- d_train[d,]\r\nt_test <- d_train[-d,]\r\n```\r\n\r\n#### Model Fit\r\n\r\nWe'll plan to build a model with 500 trees. Also to check variable importance, we'll set the flag TRUE.\r\n\r\n\r\n```r\r\n## Using Random Forest Algorithm\r\n\r\nset.seed(2016)\r\nd_fit <- randomForest(as.factor(classe)~., data = t_train, importance = TRUE, ntree=500)\r\n```\r\n\r\n#### Taking a look at the model \r\n\r\n```r\r\nd_fit\r\n```\r\n\r\n```\r\n## \r\n## Call:\r\n##  randomForest(formula = as.factor(classe) ~ ., data = t_train,      importance = TRUE, ntree = 500) \r\n##                Type of random forest: classification\r\n##                      Number of trees: 500\r\n## No. of variables tried at each split: 7\r\n## \r\n##         OOB estimate of  error rate: 0.58%\r\n## Confusion matrix:\r\n##      A    B    C    D    E  class.error\r\n## A 3346    2    0    0    0 0.0005973716\r\n## B    9 2263    7    0    0 0.0070206231\r\n## C    0   12 2039    3    0 0.0073028238\r\n## D    0    0   23 1906    1 0.0124352332\r\n## E    0    0    2    9 2154 0.0050808314\r\n```\r\nFrom above it's observed that the Out-Of-Bag error rate is `0.58%`.\r\nWe also see that the model is built with 7 variables at each split.\r\n\r\n#### Variable Importance Plot\r\nHere lets observe which features were considered in the model and it's importance as given by Accuracy metric.\r\n\r\n```r\r\nvarImpPlot(d_fit, sort = TRUE, n.var = 15 , main = \"Variable Importance Plot\", pch=16, type = 1)\r\n```\r\n\r\n<img src=\"Analysis_files/figure-html/unnamed-chunk-10-1.png\" title=\"\" alt=\"\" width=\"672\" />\r\n\r\n#### Validating the model\r\nHere we'll predict the `classe` outcome for out partitioned test data from the training set. \r\nThis will confirmation if the model is a good fit or not.\r\nRunning the confusion matrix gives us the Accuracy, Sensitivity and Specificity of the predictions.\r\n\r\n\r\n```r\r\npred_t_test <- predict(d_fit, t_test, type=\"class\")\r\np<- data.frame(pred_t_test, stringsAsFactors = FALSE)\r\nconfusionMatrix(t_test$classe, p$pred_t_test)\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 2227    1    0    0    4\r\n##          B   17 1496    5    0    0\r\n##          C    0   13 1354    1    0\r\n##          D    0    0    5 1279    2\r\n##          E    0    0    0    1 1441\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9938          \r\n##                  95% CI : (0.9918, 0.9954)\r\n##     No Information Rate : 0.286           \r\n##     P-Value [Acc > NIR] : < 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9921          \r\n##  Mcnemar's Test P-Value : NA              \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9924   0.9907   0.9927   0.9984   0.9959\r\n## Specificity            0.9991   0.9965   0.9978   0.9989   0.9998\r\n## Pos Pred Value         0.9978   0.9855   0.9898   0.9946   0.9993\r\n## Neg Pred Value         0.9970   0.9978   0.9985   0.9997   0.9991\r\n## Prevalence             0.2860   0.1925   0.1738   0.1633   0.1844\r\n## Detection Rate         0.2838   0.1907   0.1726   0.1630   0.1837\r\n## Detection Prevalence   0.2845   0.1935   0.1744   0.1639   0.1838\r\n## Balanced Accuracy      0.9958   0.9936   0.9953   0.9987   0.9978\r\n```\r\nFrom above metrics, it appears that our model Accuracy of 99%.\r\nThis is a very confident measure, so now we can run the test dataset on this model for prediction.\r\n\r\n#### Predicting on the given test dataset.\r\n\r\n```r\r\npred_pml_test <- predict(d_fit, pml_test, type=\"class\")\r\npred_pml_test\r\n```\r\n\r\n```\r\n##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 \r\n##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B \r\n## Levels: A B C D E\r\n```\r\n\r\n#### Generate Prediction Submission Files\r\n\r\n```r\r\npml_write_files = function(x){\r\n  n = length(x)\r\n  for(i in 1:n){\r\n    filename = paste0(\"problem_id_\",i,\".txt\")\r\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\r\n  }\r\n}\r\n\r\n# Run the function to generate the submission files.\r\npml_write_files(pred_pml_test)\r\n```\r\n\r\n## Summary\r\n\r\nThe estimated error rate of our model is quite low 0.58% and the cross validation Accuracy is 99%. We can conclude that the predictions on Test Dataset will be quite accurate.\r\n\r\n\r\n```\r\n##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 \r\n##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B \r\n## Levels: A B C D E\r\n```\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}